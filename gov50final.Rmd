---
title: "Gov 50 Final Project"
author: "Julia Dan"
description: "Gov 50 Final Project"
output:
  distill::distill_article:
    self_contained: false
---



## Project thoughts

Introduction

Movies are the way of the future. With hundreds of movies being released in the United States per year alone, studios must compete to win the attention of viewers. In more recent years, companies such as Netflix, Amazon Prime, and HBO Max have been employing statistics and data analytics to measure the success of their films, collecting data to determine audience preference. The film industry itself is huge, generating billions of dollars in revenue and attracting audiences worldwide. From a young age, I have always been interested in films, from wanting to be an actor to making my own original work. My personal experience with film has led me to realize that there is much more work that goes into making a great movie than meets the eye. A great movie requires top-notch actors, a brilliant story, and a dedicated production team. However, movies are also subjected to the ever-changing will of the general public. My goal with this project is to answer the research question: by what factors is a successful film defined? I hypothesize that the films with the highest prodution cost will have the highest Metacritic score, since the bigger the film's budget, the more likely it is to get a popular score from "the world's best critics". I also predict that a higher production cost will yield better critic reviews since production studios had more funds to get the best talent, crew, and promotional team in order to make the movie a success.

This investigation is important as it will reveal whether monetary success can viably correlate to the way critics perceive a film. This is significant because, though it is an observational study and thus no causation can be immediately determined, I believe that it could help to better understand the dynamics of Hollywood and reflect what we as a society value in the media we consume.


Data section

The data I chose to manipulate comes from Kaggle. Specifically, I used a data set called top-500-movies which I then merged with one called Top_1000_Highest_Grossing_Movies_Of_All_Time to create a data set that included both the elements I needed to determine the production costs of various films, the worldwide gross, and Metacritic score of these films as well as data on the films themselves like their title and their duration. Now, I have data that includes everything I need to make my primary analysis regarding budgeting, gross, and reviews. I will compare everything against the Metacritic score, my independent variable. When I run my regression of the effects of production cost on critic score, a positive, significant coefficient would indicate support for my hypothesis.

Below, the code showing the data I merged can be found.

```{r merge-data}
library(readr)
top_500_movies <- read_csv("~/Desktop/Gov 50 Final Project/index_files/sources/Data/top-500-movies.csv")

Top_1000_Highest_Grossing_Movies_Of_All_Time <-read_csv("~/Desktop/Gov 50 Final Project/index_files/sources/Data/Top_1000_Highest_Grossing_Movies_Of_All_Time.csv")

movie_data <- ("~/Desktop/Gov 50 Final Project/index_files/sources/Data/movie_data.csv")

View(top_500_movies)

## Merged data between top-500-movies and top-1000-highest-grossing-movies-of-all-time in order to get a dataset that includes all elements I will be examining
merged_data <- merge(top_500_movies, Top_1000_Highest_Grossing_Movies_Of_All_Time, by.x = "title", by.y = "Movie Title")

## Remove duplicate titles
library(readr)
library(dplyr)
gov50movies <- merged_data |>
  distinct(title, .keep_all = TRUE)
```

After merging my data, I decided to plot the relationship between production cost and Metascore, drawing a regression line in the midst of the scatterplot. Based on the graph below, I can see a minor positive correlation between these two variables, meaning that, as production cost increases, Metascore also increases slightly. Upon seeing these results, however, I was a bit less sure about the strength of this correlation, and decided to venture further into the analysis to figure out whether a correlation actually existed between production cost and  Metacritic score. To do this, I needed to run a regression and figure out what exactly are the significant coeficients within my data, and if production cost is really one of them.

```{r}
library(readr)
movie_data <- read_csv("~/Desktop/Gov 50 Final Project/index_files/sources/Data/movie_data.csv")
View(movie_data)
```

```{r}
write.csv(gov50movies, "~/Desktop/Gov 50 Final Project/index_files/sources/Data/gov50movies.csv", row.names = FALSE)
```

```{r scatterplot-production-cost-vs-metascore}
## Plotting production cost vs movie rating

library(readr)
library(ggplot2)

# Read the dataset
gov50_movies <- read_csv("~/Desktop/Gov 50 Final Project/index_files/sources/Data/gov50movies.csv")

## as.numeric
gov50_movies$production_cost <- as.numeric(gov50_movies$production_cost)
gov50_movies$Metascore <- as.numeric(gov50_movies$Metascore)

# Adjust production cost to be in tens of millions
gov50_movies$production_cost <- gov50_movies$production_cost / 10000000

# Create the scatter plot 
ggplot(gov50_movies, aes(x = Metascore, y = production_cost)) +
    geom_point(color = "lightblue") +
    theme_classic() +
    labs(title = "Movie Rating vs Production Cost",
         x = "Metascore",
         y = "Production Cost") + geom_smooth(method = "lm", se = FALSE) +
  geom_rug() +
  theme_grey()
```

Results section

As it turns out by my visualization below, my coefficient of interest was not statistically significant. I know this because I assigned a star value (from * being the least significant to *** being the most significant). This was done based on the assigned p-values from highest to lowest threshold. The p-value itself signifies the probability that, when a null hypothesis is true, the statistical significance will be either equal to or more inaccurate to the actual observed results.

First, however, I wanted to see whether there could possibly be another coefficient I could observe to draw conclusions from my analysis. I decided that worldwide gross revenue would be a good observable outcome that could yeild significant results. My rationale was that, the more money a production company yeilds from a film (aka their box-office success) represents the amount of people who have gone to see it. As such, popularity could correlate to a good critic score. Nonetheless, I was still doubtful that any result would be found from this specific analysis, since popular films that appeal to the general public do not always appeal to a critical eye. 

I chose here to observe via a histogram the preliminary visualization of number of films and their worldwide gross. Based on my results, I found that my data was heavily right-skewed and needed to be calibrated.

## visualization of skewed
```{r histogram-skewed}
hist(gov50movies$worldwide_gross, 
     main = "Histogram of Worldwide Gross of Films", 
     xlab = "Worldwide Gross of Films", 
     ylab = "Number of Films", 
     col = c("red", "orange", "yellow", "green", "purple", "magenta"))
```

To remedy my skewed data and create an output of meaningful results, 

```{r using-log}
## since data is skewed, too low, we use log
model <- lm(Metascore ~ log(worldwide_gross), data = gov50movies)

model2 <- lm(Metascore ~ log(worldwide_gross) + production_cost, data = gov50movies)
modelsummary::modelsummary(list(model, model2), stars = TRUE)

summary(model)

plot(gov50movies$Metascore, gov50movies$production_cost, main = "Scatterplot of Metascore vs Production Cost (log-transformed)")
```
null hypothesis = smth...

worlwide = indepvariable
production = control variable

Mention: observational data, cannot argue causal relationship. to improve model, using first main variable then other variable for confounding variables. 



```{r}
library(ggplot2)
model3 <- lm(Metascore ~ log(worldwide_gross) + Duration, data = gov50movies)
plot(gov50movies$Metascore, gov50movies$Duration, main = "Scatterplot",
     xlab = "Metascore", ylab = "Duration")
```

```{r}
library(readr)
library(ggplot2)

# Read the dataset
gov50_movies <- read_csv("~/Desktop/Gov 50 Final Project/index_files/sources/Data/gov50movies.csv")

# Convert 'gross' to numeric if it's not already
##remove currency??
gov50_movies$worldwide_gross <- as.numeric(gov50_movies$worldwide_gross)

# Scale gross to be in tens of millions
gov50_movies$gross <- gov50_movies$worldwide_gross / 10000000

# Create the scatter plot with a line of best fit
ggplot(gov50_movies, aes(x = year, y = worldwide_gross)) +
    geom_point() +
    geom_smooth(method = "lm", color = "blue") + # Adds a linear regression line
    theme_minimal() +
    labs(title = "Year Released vs Gross (in Tens of Millions)",
         x = "Year Released",
         y = "Worldwide Gross (Tens of Millions)")
```

```{r}
## How many of the higest grossing movies have won Oscars?

library(readr)
the_oscar_award <- read_csv("~/Desktop/Gov 50 Final Project/index_files/sources/Data/the_oscar_award.csv")
View(the_oscar_award)

# Load the required library
library(readr)
library(dplyr)

# Read the datasets
gov50_movies <- read_csv("~/Desktop/Gov 50 Final Project/index_files/sources/Data/gov50movies.csv")
oscar_awards <- read_csv("~/Desktop/Gov 50 Final Project/index_files/sources/Data/the_oscar_award.csv")

# Merge the datasets on the movie title
# Replace 'movie_title_column' with the actual column names if they are different
oscar_gov <- merge(gov50movies, oscar_awards, by.x = "title", by.y = "film")

## Selecting only specific columns for Oscars
oscar_gov |> 
  select(winner, category, Metascore, title)

## filter by winners only

oscar_gov |> filter(winner == TRUE)

## Now figure out what percentage of overall highest-grossing films are Oscar-winners

threshold <- 85

# Filter to get highest-rated films
highest_rated_films <- filter(oscar_gov, Metascore > threshold)

# Count the total number of highest-rated films
total_highest_rated <- nrow(highest_rated_films)

# Count the number of Oscar winners among the highest-rated films
oscar_winners_highest_rated <- sum(highest_rated_films$winner == TRUE)

# Calculate the percentage of highest-rated films that are Oscar winners
percentage_oscar_winners <- (oscar_winners_highest_rated / total_highest_rated) * 100

# Print the result
print(paste("Percentage of highest-rated films that are Oscar winners: ", percentage_oscar_winners, "%", sep = ""))

```

```{r}
## merging data, oscars and gov50movies with left-join instead of merge --> THIS WORKS!

# Read the datasets
gov50_movies <- read_csv("~/Desktop/Gov 50 Final Project/index_files/sources/Data/gov50movies.csv")
oscar_awards <- read_csv("~/Desktop/Gov 50 Final Project/index_files/sources/Data/the_oscar_award.csv")

# Rename for consistency
gov50_movies <- gov50_movies |> rename("Movie Title" = title)
oscar_awards <- oscar_awards |> rename("Movie Title" = film)

# Left join
merged_data <- gov50_movies |> 
  left_join(oscar_awards, by = "Movie Title") |>
  select(winner, category, Metascore, "Movie Title")
```